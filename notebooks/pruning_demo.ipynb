{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b901618f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "\n",
    "import torchmetrics\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelPruning\n",
    "\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90657d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def get_digits():\n",
    "\n",
    "    dataset = sklearn.datasets.load_digits()\n",
    "\n",
    "    data_x = dataset[\"data\"]\n",
    "    data_y = dataset[\"target\"]\n",
    "\n",
    "    default_dtype = torch.get_default_dtype()\n",
    "\n",
    "    data_x = torch.tensor(data_x, dtype=default_dtype)\n",
    "    data_y = torch.tensor(data_y, dtype=torch.long)\n",
    "\n",
    "    return data_x, data_y\n",
    "\n",
    "def get_compute_pruning_rate(schedule=[(100, 0.5)]):\n",
    "    \n",
    "    def compute_pruning_rate(epoch):\n",
    "        for threshold_epoch, rate in schedule:\n",
    "            if epoch == threshold_epoch:\n",
    "                msg = f\"prune at rate {rate} epoch {epoch}\"\n",
    "                print(msg)\n",
    "                return rate\n",
    "\n",
    "    return compute_pruning_rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f007a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model\n",
    "\n",
    "class DigitsModel(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.learning_rate = kwargs[\"lr\"] \\\n",
    "                if \"lr\" in kwargs.keys() else 3e-4\n",
    "        self.dim_in = kwargs[\"dim_in\"] \\\n",
    "                if \"dim_in\" in kwargs.keys() else 64\n",
    "        self.number_classes = kwargs[\"number_classes\"]\\\n",
    "                if \"number_classes\" in kwargs.keys() else 10\n",
    "        self.dim_h = kwargs[\"dim_h\"]\\\n",
    "                if \"dim_h\" in kwargs.keys() else 256\n",
    "        self.l2_penalty = kwargs[\"l2\"] \\\n",
    "                if \"l2\" in kwargs.keys() else 0.0\n",
    "        self.dropout_rate = kwargs[\"dropout_rate\"]\\\n",
    "                if \"dropout_rate\" in kwargs.keys() else 0.0\n",
    "\n",
    "        \n",
    "\n",
    "        self.layer_0 = nn.Linear(self.dim_in, self.dim_h)\n",
    "        self.layer_1 = nn.Linear(self.dim_h, self.dim_h)\n",
    "        self.layer_2 = nn.Linear(self.dim_h, self.dim_h)\n",
    "        self.layer_3 = nn.Linear(self.dim_h, self.dim_h)\n",
    "        self.layer_4 = nn.Linear(self.dim_h, self.dim_h)\n",
    "        self.layer_out = nn.Linear(self.dim_h, self.number_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = torch.relu(self.layer_0(x))\n",
    "        x = torch.relu(self.layer_1(x))\n",
    "        x = F.dropout(x, p=self.dropout_rate, \\\n",
    "                training=self.training)\n",
    "        x = torch.relu(self.layer_2(x))\n",
    "        x = F.dropout(x, p=self.dropout_rate, \\\n",
    "                training=self.training)\n",
    "        x = torch.relu(self.layer_3(x))\n",
    "        x = F.dropout(x, p=self.dropout_rate, \\\n",
    "                training=self.training)\n",
    "        x = torch.relu(self.layer_4(x))\n",
    "        x = F.dropout(x, p=self.dropout_rate, \\\n",
    "                training=self.training)\n",
    "\n",
    "        output = self.layer_out(x)\n",
    "\n",
    "        return output\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        \n",
    "        data_x, targets = batch[0], batch[1]\n",
    "\n",
    "        predictions = self.forward(data_x)\n",
    "\n",
    "        loss = F.cross_entropy(predictions, targets)\n",
    "        accuracy = torchmetrics.functional.accuracy(predictions, targets)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        self.log(\"train_accuracy\", accuracy)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        \n",
    "        data_x, targets = batch[0], batch[1]\n",
    "\n",
    "        predictions = self.forward(data_x)\n",
    "\n",
    "        validation_loss = F.cross_entropy(predictions, targets)\n",
    "        validation_accuracy = torchmetrics.functional.accuracy(predictions, targets)\n",
    "        self.log(\"val_loss\", validation_loss)\n",
    "        self.log(\"val_accuracy\", validation_accuracy)\n",
    "    \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        optimizer = torch.optim.Adam(self.parameters(), \\\n",
    "                lr=self.learning_rate, \\\n",
    "                weight_decay=self.l2_penalty)\n",
    "\n",
    "        return optimizer\n",
    "    \n",
    "    def count_params(self):\n",
    "\n",
    "        count = 0\n",
    "\n",
    "        for p in self.parameters():\n",
    "            count += p.numel() \n",
    "\n",
    "        return count\n",
    "\n",
    "    def count_pruned(self):\n",
    "\n",
    "        count_active = 0\n",
    "\n",
    "        for name, p in self.named_parameters():\n",
    "            \n",
    "            count_active += torch.sum(p != 0.0)\n",
    "\n",
    "        total_count = self.count_params()\n",
    "        prune_msg = f\"{count_active} nonzero of\"\\\n",
    "                f\" {total_count} parameters, \"\\\n",
    "                f\"{count_active/total_count:.4e}\"\n",
    "        print(prune_msg)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7218ecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment/Demo\n",
    "\n",
    "# Magic numbers\n",
    "max_epochs = 256\n",
    "num_workers = 2\n",
    "batch_size = 128\n",
    "dropout_rate = 0.5\n",
    "l2 = 1e-6\n",
    "lr=1e-4\n",
    "dim_h = 1024\n",
    "my_seeds = [1, 13, 42] \n",
    "\n",
    "# run experiment\n",
    "\n",
    "data_x, target = get_digits()\n",
    "\n",
    "for use_pruning in [True, False]:\n",
    "\n",
    "\n",
    "    if use_pruning:\n",
    "        pruning_schedule = [(elem, 0.495) \\\n",
    "                for elem in range(100,201,33)]\n",
    "    else:\n",
    "        pruning_schedule = []\n",
    "\n",
    "\n",
    "    for my_seed in my_seeds:    \n",
    "        np.random.seed(my_seed)\n",
    "        torch.manual_seed(my_seed)\n",
    "\n",
    "\n",
    "        model = DigitsModel(dropout_rate=dropout_rate, \\\n",
    "                dim_h=dim_h, l2=l2, lr=lr)\n",
    "\n",
    "        model(data_x)\n",
    "\n",
    "        test_x, test_y = data_x[-100:], target[-100:]\n",
    "        dataset = TensorDataset(data_x[:400], target[:400]) \n",
    "        val_dataset = TensorDataset(\\\n",
    "                data_x[-400:-100], target[-400:-100]) \n",
    "        train_dataloader = DataLoader(dataset, \\\n",
    "                batch_size=batch_size, \\\n",
    "                num_workers=num_workers)\n",
    "        val_dataloader = DataLoader(val_dataset, \\\n",
    "                batch_size=batch_size, \\\n",
    "                num_workers=num_workers)\n",
    "\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            trainer = pl.Trainer(accelerator=\"gpu\", \\\n",
    "                    devices=1, max_epochs=max_epochs,\\\n",
    "                    callbacks=[ModelPruning(\"l1_unstructured\",\\\n",
    "                    amount=get_compute_pruning_rate())])\n",
    "        else:\n",
    "            trainer = pl.Trainer(max_epochs=max_epochs,\\\n",
    "                    callbacks=[ModelPruning(\"l1_unstructured\",\\\n",
    "                    amount=get_compute_pruning_rate(\\\n",
    "                    schedule=pruning_schedule))])\n",
    "\n",
    "        model.count_pruned()\n",
    "\n",
    "        trainer.fit(model=model, \\\n",
    "                train_dataloaders=train_dataloader,\\\n",
    "                val_dataloaders=val_dataloader)\n",
    "\n",
    "\n",
    "        model.count_pruned()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
